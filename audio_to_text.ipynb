{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VOSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "input overflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped listening\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import vosk\n",
    "import json\n",
    "import sys\n",
    "\n",
    "model_path1 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\"\n",
    "model_path2 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\"\n",
    "\n",
    "model = vosk.Model(model_path1)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "buffered_text = \"\"\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    global buffered_text\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_data = bytes(indata)\n",
    "    if recognizer.AcceptWaveform(audio_data):\n",
    "        result = recognizer.Result()\n",
    "        result_dict = json.loads(result)\n",
    "        text = result_dict.get(\"text\", \"\")\n",
    "        if text:\n",
    "            buffered_text = \"\" \n",
    "    else:\n",
    "        partial_result = recognizer.PartialResult()\n",
    "        result_dict = json.loads(partial_result)\n",
    "        partial_text = result_dict.get(\"partial\", \"\")\n",
    "        buffered_text += partial_text\n",
    "\n",
    "with sd.RawInputStream(samplerate=16000, blocksize=4096, dtype='int16', channels=1, callback=callback):\n",
    "    print(\"Listening...\")\n",
    "    try:\n",
    "        while True:\n",
    "            sd.sleep(1000)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped listening\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "hey\n",
      "i've always\n",
      "try to handle myself with this much class and it's\n",
      "check yourself\n",
      "into the issue\n",
      "stop\n",
      "don't you will\n",
      "new\n",
      "two\n",
      "shipping larger sized dog\n",
      "for for walk out the door so long walk out know the past\n",
      "you know\n",
      "right\n",
      "the\n",
      "week\n",
      "over your body\n",
      "hey\n",
      "several that one\n",
      "month\n",
      "on your computer voice does google dot com\n",
      "this thread reader\n",
      "go to your settings for the main menu and preventer\n",
      "to move to the accessibility infection the upper new an arrow keys\n",
      "that one\n",
      "Stopped listening\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import vosk\n",
    "import json\n",
    "import sys\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "model_path1 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\"\n",
    "model_path2 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\"\n",
    "\n",
    "model = vosk.Model(model_path1)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "buffered_text = \"\"\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(bytes(indata))\n",
    "\n",
    "def recognition_thread():\n",
    "    global buffered_text\n",
    "    while True:\n",
    "        audio_data = audio_queue.get()\n",
    "        if recognizer.AcceptWaveform(audio_data):\n",
    "            result = recognizer.Result()\n",
    "            result_dict = json.loads(result)\n",
    "            text = result_dict.get(\"text\", \"\")\n",
    "            if text:\n",
    "                print(text) \n",
    "                buffered_text = \"\" \n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            result_dict = json.loads(partial_result)\n",
    "            partial_text = result_dict.get(\"partial\", \"\")\n",
    "            buffered_text += partial_text\n",
    "\n",
    "recognition_thread = threading.Thread(target=recognition_thread, daemon=True)\n",
    "recognition_thread.start()\n",
    "\n",
    "with sd.RawInputStream(samplerate=16000, blocksize=4096, dtype='int16', channels=1, callback=callback):\n",
    "    print(\"Listening...\")\n",
    "    try:\n",
    "        while True:\n",
    "            sd.sleep(1000)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped listening\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognized text: the the the the the the the the the the the the the the the the the the the the the the the most the the must stand up the must stand up to the the must stand up to the the must stand up to the world the must stand up to the world the must stand up to the world the must stand up to the world the media must stand up to the world because because like because i believe because i believe that because i believe that unless because i believe that unless because i believe that unless india because i believe that unless india standard because i believe that unless india stands because i believe that unless india stands up to because i believe that unless india stands up to the because i believe that unless india stands up to the world because i believe that unless india stands up to the world because i believe that unless india stands up to the world no one because i believe that unless india stands up to the world no one will because i believe that unless india stands up to the world no one will because i believe that unless india stands up to the world no one will respect because i believe that unless india stands up to the world no one will respect us because i believe that unless india stands up to the world no one will respect us because i believe that unless india stands up to the world no one will respect us because i believe that unless india stands up to the world no one will respect us because i believe that unless india stands up to the world no one will respect us because i believe that unless india stands up to the world no one will respect us only because i believe that unless india stands up to the world no one will respect us only because i believe that unless india stands up to the world no one will respect us only strength because i believe that unless india stands up to the world no one will respect us only strength because i believe that unless india stands up to the world no one will respect us only strength respect because i believe that unless india stands up to the world no one will respect us only strength respect strength because i believe that unless india stands up to the world no one will respect us only strength respect strength because i believe that unless india stands up to the world no one will respect us only strength respect strength because i believe that unless india stands up to the world no one will respect us only strength respect strength because i believe that unless india stands up to the world no one will respect us only strength respect strength because i believe that unless india stands up to the world no one will respect us only strength respect strength we because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be strong because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be strong not because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be strong not only because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be strong not only is a because i believe that unless india stands up to the world no one will respect us only strength respect strength we must be strong not only is the military\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import vosk\n",
    "import json\n",
    "import sys\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "model_path1 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\"\n",
    "model_path2 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\"\n",
    "\n",
    "model = vosk.Model(model_path2)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "buffered_text = \"\"\n",
    "audio_queue = queue.Queue()\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(bytes(indata))\n",
    "\n",
    "def recognition_thread():\n",
    "    global buffered_text\n",
    "    while not stop_event.is_set() or not audio_queue.empty():\n",
    "        try:\n",
    "            audio_data = audio_queue.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "        if recognizer.AcceptWaveform(audio_data):\n",
    "            result = recognizer.Result()\n",
    "            result_dict = json.loads(result)\n",
    "            text = result_dict.get(\"text\", \"\")\n",
    "            if text:\n",
    "                buffered_text += text + \" \"\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            result_dict = json.loads(partial_result)\n",
    "            partial_text = result_dict.get(\"partial\", \"\")\n",
    "            buffered_text += partial_text + \" \"\n",
    "\n",
    "def record_and_recognize(duration):\n",
    "    global buffered_text\n",
    "    buffered_text = \"\"\n",
    "    \n",
    "    recognition_thread_instance = threading.Thread(target=recognition_thread, daemon=True)\n",
    "    recognition_thread_instance.start()\n",
    "\n",
    "    with sd.RawInputStream(samplerate=16000, blocksize=4096, dtype='int16', channels=1, callback=callback):\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            time.sleep(duration)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopped listening\")\n",
    "\n",
    "    stop_event.set()\n",
    "    recognition_thread_instance.join()\n",
    "\n",
    "    return buffered_text.strip()\n",
    "\n",
    "\n",
    "record_duration = 20\n",
    "recognized_text = record_and_recognize(record_duration)\n",
    "print(f\"Recognized text: {recognized_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognized text: in the my stand up to the world because i believe that in left in the of hands up to the world no one will respect us only string respect stream we must be strong not only is military power but also in the economic power\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import vosk\n",
    "import json\n",
    "import sys\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "model_path1 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\"\n",
    "model_path2 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\"\n",
    "\n",
    "model = vosk.Model(model_path1)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "buffered_text = \"\"\n",
    "audio_queue = queue.Queue()\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(bytes(indata))\n",
    "\n",
    "def recognition_thread():\n",
    "    global buffered_text\n",
    "    last_partial = \"\"\n",
    "    while not stop_event.is_set() or not audio_queue.empty():\n",
    "        try:\n",
    "            audio_data = audio_queue.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "        if recognizer.AcceptWaveform(audio_data):\n",
    "            result = recognizer.Result()\n",
    "            result_dict = json.loads(result)\n",
    "            text = result_dict.get(\"text\", \"\")\n",
    "            if text:\n",
    "                buffered_text += text + \" \"\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            result_dict = json.loads(partial_result)\n",
    "            partial_text = result_dict.get(\"partial\", \"\")\n",
    "            if partial_text and partial_text != last_partial:\n",
    "                last_partial = partial_text\n",
    "\n",
    "def record_and_recognize(duration):\n",
    "    global buffered_text\n",
    "    buffered_text = \"\"\n",
    "    \n",
    "    recognition_thread_instance = threading.Thread(target=recognition_thread, daemon=True)\n",
    "    recognition_thread_instance.start()\n",
    "\n",
    "    with sd.RawInputStream(samplerate=16000, blocksize=4096, dtype='int16', channels=1, callback=callback):\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            time.sleep(duration)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopped listening\")\n",
    "\n",
    "    stop_event.set()\n",
    "    recognition_thread_instance.join()\n",
    "\n",
    "    return buffered_text.strip()\n",
    "\n",
    "\n",
    "record_duration = 30 \n",
    "recognized_text = record_and_recognize(record_duration)\n",
    "print(f\"Recognized text: {recognized_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Failed to create a model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model_path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSpectoV\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHand_Gesture_Recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresearch\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlevel_2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvosk-model-small-en-us-0.15\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvosk-model-small-en-us-0.15\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m model_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSpectoV\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHand_Gesture_Recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresearch\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlevel_2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvosk-model-en-us-0.22\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvosk-model-en-us-0.22\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvosk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m vosk\u001b[38;5;241m.\u001b[39mKaldiRecognizer(model, \u001b[38;5;241m16000\u001b[39m)\n\u001b[0;32m     15\u001b[0m buffered_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\SpectoV\\Hand_Gesture_Recognition\\.venv\\Lib\\site-packages\\vosk\\__init__.py:57\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model_path, model_name, lang)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _c\u001b[38;5;241m.\u001b[39mvosk_model_new(model_path\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create a model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Failed to create a model"
     ]
    }
   ],
   "source": [
    "import vosk\n",
    "import queue\n",
    "import json\n",
    "import threading\n",
    "import sounddevice as sd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "model_path1 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\"\n",
    "model_path2 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\"\n",
    "\n",
    "model = vosk.Model(model_path2)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "buffered_text = \"\"\n",
    "audio_queue = queue.Queue()\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "def recognition_thread():\n",
    "    global buffered_text\n",
    "    last_partial = \"\"\n",
    "    while not stop_event.is_set() or not audio_queue.empty():\n",
    "        try:\n",
    "            audio_data = audio_queue.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "        if recognizer.AcceptWaveform(audio_data.tobytes()):\n",
    "            result = recognizer.Result()\n",
    "            result_dict = json.loads(result)\n",
    "            text = result_dict.get(\"text\", \"\")\n",
    "            if text:\n",
    "                buffered_text += text + \" \"\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            result_dict = json.loads(partial_result)\n",
    "            partial_text = result_dict.get(\"partial\", \"\")\n",
    "            if partial_text and partial_text != last_partial:\n",
    "                last_partial = partial_text\n",
    "                print(\"Partial Result:\", partial_text)\n",
    "\n",
    "def record_and_recognize(duration):\n",
    "    global buffered_text\n",
    "    buffered_text = \"\"\n",
    "    \n",
    "    recognition_thread_instance = threading.Thread(target=recognition_thread, daemon=True)\n",
    "    recognition_thread_instance.start()\n",
    "\n",
    "    with sd.InputStream(samplerate=16000, blocksize=4096, dtype='int16', channels=1, callback=callback):\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            time.sleep(duration)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopped listening\")\n",
    "\n",
    "    stop_event.set()\n",
    "    recognition_thread_instance.join()\n",
    "\n",
    "    return buffered_text.strip()\n",
    "\n",
    "def recognize_from_audio_file(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "\n",
    "    if recognizer.AcceptWaveform(audio_data):\n",
    "        result = recognizer.Result()\n",
    "        result_dict = json.loads(result)\n",
    "        return result_dict.get(\"text\", \"\")\n",
    "    else:\n",
    "        return \"Recognition failed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Partial Result: the\n",
      "Partial Result: i this\n",
      "Partial Result: i this is\n",
      "Partial Result: i this is a\n",
      "Partial Result: i this is ha\n",
      "Partial Result: i this is ha with\n",
      "Partial Result: i this is ha with another\n",
      "Partial Result: i this is ha with another effortless\n",
      "Partial Result: i this is ha with another effortless english\n",
      "Partial Result: i this is ha with another effortless english podcast\n",
      "Partial Result: so\n",
      "Partial Result: so today is\n",
      "Partial Result: so today is monday\n",
      "Partial Result: so today is monday and\n",
      "Partial Result: so today is monday and i'm\n",
      "Partial Result: so today is monday and i'm here\n",
      "Partial Result: so today is monday and i'm here in\n",
      "Partial Result: so today is monday and i'm here in san\n",
      "Partial Result: so today is monday and i'm here in san francisco\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching council\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching conference\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching conference and\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching conference and the\n",
      "Partial Result: so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching conference and the leader\n",
      "Partial Result: of the\n",
      "Partial Result: of the teaching\n",
      "Partial Result: of the teaching conference\n",
      "Partial Result: of the teaching conference was\n",
      "Partial Result: of the teaching conference was blaine\n",
      "Partial Result: of the teaching conference was blaine re\n",
      "Partial Result: and\n",
      "Partial Result: at first\n",
      "Partial Result: at first i just want to\n",
      "Partial Result: at first i just wanna say\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i this is ha with another effortless english podcast so today is monday and i'm here in san francisco i'm back in san francisco last week we were in texas we were at a teaching conference and the leader of the teaching conference was blaine ray\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_and_recognize(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
