{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import sounddevice as sd\n",
    "import vosk\n",
    "import sys\n",
    "import threading\n",
    "import queue\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:\\SpectoV\\Hand_Gesture_Recognition\\data\\level_1_data\\ASL_Data_AtoZ_&_0to9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(image_array):\n",
    "    pil_img = Image.fromarray(image_array)\n",
    "    buffer = io.BytesIO()\n",
    "    pil_img.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    image_dict = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            sign = os.path.splitext(filename)[0] \n",
    "            img_path = os.path.join(folder, filename)\n",
    "            image = Image.open(img_path)\n",
    "            image_array = np.array(image)\n",
    "            image_dict[sign] = image_array\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_images_to_base64(image_dict):\n",
    "    base64_dict = {}\n",
    "    for sign, image_array in image_dict.items():\n",
    "        base64_dict[sign] = image_to_base64(image_array)\n",
    "    return base64_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_as_json(data_dict, output_path):\n",
    "    with open(output_path, 'w') as json_file:\n",
    "        json.dump(data_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_path = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\asl_signs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_path, output_json_path):\n",
    "    image_dict = load_images_from_folder(dataset_path)\n",
    "    base64_dict = convert_images_to_base64(image_dict)\n",
    "    save_dict_as_json(base64_dict, output_json_path)\n",
    "    print(f\"Data saved to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\asl_signs.json\n"
     ]
    }
   ],
   "source": [
    "main(dataset_path,output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base64_to_image(base64_str):\n",
    "    try:\n",
    "        image_data = base64.b64decode(base64_str)\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        \n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting base64 to image: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_for_string(input_string, data_dict):\n",
    "    input_string = input_string.upper()\n",
    "    for char in input_string:\n",
    "        if char in data_dict:\n",
    "            image_base64 = data_dict[char]\n",
    "            image = base64_to_image(image_base64)\n",
    "            image.show()\n",
    "            time.sleep(2)\n",
    "            image.close()\n",
    "        else: \n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-small-en-us-0.15\\vosk-model-small-en-us-0.15\"\n",
    "model_path2 = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\vosk-model-en-us-0.22\\vosk-model-en-us-0.22\"\n",
    "\n",
    "model = vosk.Model(model_path2)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "\n",
    "buffered_text = \"\"\n",
    "audio_queue = queue.Queue()\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    audio_queue.put(bytes(indata))\n",
    "\n",
    "def recognition_thread():\n",
    "    global buffered_text\n",
    "    last_partial = \"\"\n",
    "    while not stop_event.is_set() or not audio_queue.empty():\n",
    "        try:\n",
    "            audio_data = audio_queue.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "        if recognizer.AcceptWaveform(audio_data):\n",
    "            result = recognizer.Result()\n",
    "            result_dict = json.loads(result)\n",
    "            text = result_dict.get(\"text\", \"\")\n",
    "            if text:\n",
    "                buffered_text += text + \" \"\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            result_dict = json.loads(partial_result)\n",
    "            partial_text = result_dict.get(\"partial\", \"\")\n",
    "            if partial_text and partial_text != last_partial:\n",
    "                last_partial = partial_text\n",
    "\n",
    "def record_and_recognize(duration):\n",
    "    global buffered_text\n",
    "    buffered_text = \"\"\n",
    "    \n",
    "    recognition_thread_instance = threading.Thread(target=recognition_thread, daemon=True)\n",
    "    recognition_thread_instance.start()\n",
    "\n",
    "    with sd.RawInputStream(samplerate=16000, blocksize=4096, dtype='int16', channels=1, callback=callback):\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            time.sleep(duration)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopped listening\")\n",
    "\n",
    "    stop_event.set()\n",
    "    recognition_thread_instance.join()\n",
    "\n",
    "    return buffered_text.strip()\n",
    "\n",
    "def recognize_from_audio_file(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "\n",
    "    if recognizer.AcceptWaveform(audio_data):\n",
    "        result = recognizer.Result()\n",
    "        result_dict = json.loads(result)\n",
    "        return result_dict.get(\"text\", \"\")\n",
    "    else:\n",
    "        return \"Recognition failed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(method):\n",
    "    json_path = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\asl_signs.json\"\n",
    "    audio_file_path = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_2\\audio1.mp3\"\n",
    "    data_dict = load_json(json_path)\n",
    "    if method == 'record':\n",
    "       record_duration = 10\n",
    "       recognized_text = record_and_recognize(record_duration)\n",
    "       input_string = recognized_text\n",
    "    elif method == 'audio_file':\n",
    "       recognized_text = recognize_from_audio_file(audio_file_path)\n",
    "       input_string = recognized_text\n",
    "\n",
    "    print(f\"Recognized text: {input_string}\")\n",
    "    #time.sleep(2)\n",
    "    #display_images_for_string(input_string, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognized text: the aliens be i'm a daughter of a professor she admitted daughter-in-law fourth quarter egypt and\n"
     ]
    }
   ],
   "source": [
    "main(method='record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
