{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    \"\"\"mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_CONTOURS,mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),\n",
    "                                                                                         mp_drawing.DrawingSpec(color=(80,256,121),thickness=1,circle_radius=1))\n",
    "    \n",
    "    #mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,mp_drawing.DrawingSpec(color=(80,22,10),thickness=2,circle_radius=4),\n",
    "                                                                                        mp_drawing.DrawingSpec(color=(80,44,121),thickness=2,circle_radius=2))\"\"\"\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(121,22,76),thickness=2,circle_radius=4),\n",
    "                                                                                             mp_drawing.DrawingSpec(color=(121,44,250),thickness=2,circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=4),\n",
    "                                                                                              mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cap = cv2.VideoCapture(0)\\nif not cap.isOpened():\\n    print(\"Error: Could not open video device.\")\\nelse:\\n    with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic: \\n        while cap.isOpened():\\n            ret,frame = cap.read()\\n\\n            image,results = mediapipe_detection(frame,holistic)\\n            print(results)\\n            \\n            draw_landmarks(image,results)\\n\\n            cv2.imshow(\\'OpenCV feed\\',image)\\n            if cv2.waitKey(10) & 0xFF == ord(\\'q\\'):\\n                break\\n        cap.release()\\n        cv2.destroyAllWindows()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video device.\")\n",
    "else:\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic: \n",
    "        while cap.isOpened():\n",
    "            ret,frame = cap.read()\n",
    "\n",
    "            image,results = mediapipe_detection(frame,holistic)\n",
    "            print(results)\n",
    "            \n",
    "            draw_landmarks(image,results)\n",
    "\n",
    "            cv2.imshow('OpenCV feed',image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    #pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    #face = np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh,rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_folders_in_directory():\n",
    "    directory_path = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\data\\level_1_data\\ASL_self_created_data\"\n",
    "    try:\n",
    "        items = os.listdir(directory_path)\n",
    "        folders = [item for item in items if os.path.isdir(os.path.join(directory_path, item))]\n",
    "        return folders,directory_path\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The directory {directory_path} does not exist.\")\n",
    "        return [],directory_path\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return [],directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_video_files(folder_path):\n",
    "    video_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith((\".mp4\", \".avi\", \".mkv\", \".mov\", \".wmv\")):\n",
    "            video_files.append(file)\n",
    "    return video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    key_points = []\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}.\")\n",
    "        return\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            draw_landmarks(image, results)\n",
    "\n",
    "            keypoints = extract_keypoints(results)\n",
    "            key_points.append(keypoints)\n",
    "            \n",
    "            cv2.imshow('Video Feed', image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return np.array(key_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    key_point_data_path = r\"D:\\SpectoV\\Hand_Gesture_Recognition\\research\\level_3\\key_points\"\n",
    "    actions, directory_path = list_folders_in_directory()\n",
    "    num_videos = 40\n",
    "    fps = 30\n",
    "    duration = 2\n",
    "    frame_count = fps * duration\n",
    "    for action in tqdm(actions, desc=\"Processing Actions\"):\n",
    "        path = os.path.join(directory_path, str(action))\n",
    "        videos = list_video_files(path)\n",
    "        for video in tqdm(videos, desc=f\"Processing Videos in {action}\", leave=False):\n",
    "            try:\n",
    "                action_path = os.path.join(key_point_data_path, action, str(video).split(\".\")[0])\n",
    "                os.makedirs(action_path, exist_ok=True) \n",
    "                key_points = get_keypoints(os.path.join(path, video))\n",
    "                for i,point in zip(range(1,len(key_points)+1),key_points):\n",
    "                    file_path = os.path.join(action_path,str(i))\n",
    "                    np.save(file_path, point)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Actions: 100%|██████████| 2/2 [12:15<00:00, 367.74s/it]\n"
     ]
    }
   ],
   "source": [
    "data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
