{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING SYSTEMS CAMERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI SAM\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from time import time\n",
    "import cvzone\n",
    "from screeninfo import get_monitors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "screen_width = get_monitors()[0].width\n",
    "screen_height = get_monitors()[0].height\n",
    "cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Image\", screen_width, screen_height)\n",
    "\n",
    "# Start Video Capture\n",
    "cap = cv2.VideoCapture(0)  # Adjust the camera\n",
    "cap.set(3, screen_width)\n",
    "cap.set(4, screen_height)\n",
    "\n",
    "detector = HandDetector(detectionCon=0.8)\n",
    "\n",
    "# Keyboard Layout\n",
    "keys = [\n",
    "    [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"<\"],\n",
    "    [\"Q\", \"W\", \"E\", \"R\", \"T\", \"Y\", \"U\", \"I\", \"O\", \"P\"],\n",
    "    [\"A\", \"S\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \";\"],\n",
    "    [\"Z\", \"X\", \"C\", \"V\", \"B\", \"N\", \"M\", \",\", \".\", \"/\"],\n",
    "    [\"Space\", \"Enter\"]\n",
    "]\n",
    "finalText = \"\"\n",
    "\n",
    "class Button:\n",
    "    def __init__(self, pos, text, size=[60, 60]):  # Adjusted size of the buttons\n",
    "        self.pos = pos\n",
    "        self.size = size\n",
    "        self.text = text\n",
    "\n",
    "def drawAll(img, buttonList):\n",
    "    for button in buttonList:\n",
    "        x, y = button.pos\n",
    "        w, h = button.size\n",
    "        cvzone.cornerRect(img, (button.pos[0], button.pos[1], button.size[0], button.size[1]), 10, rt=4)\n",
    "        cv2.rectangle(img, button.pos, (x + w, y + h), (255, 255, 255), cv2.FILLED)\n",
    "        cv2.putText(img, button.text, (x + 5, y + 30), cv2.FONT_HERSHEY_PLAIN, 2, (150, 150, 150), 2)\n",
    "    return img\n",
    "\n",
    "# Create button list\n",
    "buttonList = []\n",
    "for i in range(len(keys)):\n",
    "    for j, key in enumerate(keys[i]):\n",
    "        if key == \"Space\":\n",
    "            buttonList.append(Button([450, 80 * i + 90], key, size=[160, 60]))  # Adjusted size for space button\n",
    "        elif key == \"Enter\":\n",
    "            buttonList.append(Button([650, 80 * i + 90], key, size=[160, 60]))  # Adjusted position for enter button\n",
    "        else:\n",
    "            buttonList.append(Button([80 * j + 220, 100 * i + 10], key))\n",
    "\n",
    "# Variables to manage debounce and stability effect\n",
    "lastKeyPressed = None\n",
    "lastPressTime = 0\n",
    "pressCooldown = 0.5  # Time in seconds\n",
    "stableTime = 0.2  # Time in seconds\n",
    "startStableTime = None\n",
    "currentButton = None\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "    \n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "    img = drawAll(img, buttonList)\n",
    "\n",
    "    if hands:\n",
    "        lmListHand = hands[0]['lmList']\n",
    "        for button in buttonList:\n",
    "            x, y = button.pos\n",
    "            w, h = button.size\n",
    "\n",
    "            if x < lmListHand[8][0] < x + w and y < lmListHand[8][1] < y + h:\n",
    "                if currentButton != button.text:\n",
    "                    startStableTime = time()\n",
    "                    currentButton = button.text\n",
    "\n",
    "                if currentButton == button.text:\n",
    "                    if startStableTime is not None and time() - startStableTime > stableTime:\n",
    "                        cv2.rectangle(img, (x - 5, y - 5), (x + w + 5, y + h + 5), (130, 80, 70), cv2.FILLED)\n",
    "                        cv2.putText(img, button.text, (x + 10, y + 40), cv2.FONT_HERSHEY_PLAIN, 2, (200, 200,200), 2)\n",
    "\n",
    "                        l, _, _ = detector.findDistance((lmListHand[8][0], lmListHand[8][1]), \n",
    "                                                        (lmListHand[12][0], lmListHand[12][1]), img)\n",
    "\n",
    "                        currentTime = time()\n",
    "                        if l < 30 and (lastKeyPressed != button.text or (currentTime - lastPressTime) > pressCooldown):\n",
    "                            #print(f\"Key Pressed: {button.text}\")\n",
    "                            cv2.rectangle(img, button.pos, (x + w, y + h), (230,50,230), cv2.FILLED)\n",
    "                            cv2.putText(img, button.text, (x + 10, y + 40), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                            if button.text == \"<\":  # Handle backspace\n",
    "                                finalText = finalText[:-1]\n",
    "                            elif button.text == \"Space\":  # Handle space\n",
    "                                finalText += \" \"\n",
    "                            elif button.text == \"Enter\":  # Handle enter\n",
    "                                print(f\"{finalText}\")\n",
    "                                finalText = \"\"  # Clear the text after printing\n",
    "                            else:\n",
    "                                finalText += button.text\n",
    "                            lastKeyPressed = button.text\n",
    "                            lastPressTime = currentTime\n",
    "                            startStableTime = None  # Reset stable time after a key press\n",
    "\n",
    "    else:\n",
    "        currentButton = None  # Reset currentButton when no hands are detected\n",
    "\n",
    "    # Draw text box\n",
    "    #cv2.rectangle(img, (100, 550), (1150, 600), (175, 0, 175), cv2.FILLED)  # Adjusted text box position and size\n",
    "    cv2.putText(img, finalText, (50, 600), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINING KEYBOARD AND GESTURE REGOZNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to Keyboard Mode\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 266\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m lmListHand[\u001b[38;5;241m8\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m x \u001b[38;5;241m+\u001b[39m w \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m<\u001b[39m lmListHand[\u001b[38;5;241m8\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m y \u001b[38;5;241m+\u001b[39m h:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m currentButton \u001b[38;5;241m!=\u001b[39m button\u001b[38;5;241m.\u001b[39mtext:\n\u001b[1;32m--> 266\u001b[0m         startStableTime \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m         currentButton \u001b[38;5;241m=\u001b[39m button\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m currentButton \u001b[38;5;241m==\u001b[39m button\u001b[38;5;241m.\u001b[39mtext:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "import time\n",
    "import cvzone\n",
    "from screeninfo import get_monitors\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize CV2 window\n",
    "screen_width = get_monitors()[0].width\n",
    "screen_height = get_monitors()[0].height\n",
    "cv2.namedWindow(\"Hand Gesture Recognition and Keyboard\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Hand Gesture Recognition and Keyboard\", screen_width, screen_height)\n",
    "\n",
    "# Start Video Capture for Hand Gesture Recognition\n",
    "cap_gesture = cv2.VideoCapture(0)\n",
    "cap_gesture.set(3, screen_width)\n",
    "cap_gesture.set(4, screen_height)\n",
    "\n",
    "# Start Video Capture for Keyboard Input\n",
    "cap_keyboard = cv2.VideoCapture(0)  # Adjust the camera\n",
    "cap_keyboard.set(3, screen_width)\n",
    "cap_keyboard.set(4, screen_height)\n",
    "\n",
    "def calculate_angle(A, B, C):\n",
    "    \"\"\"Calculate the angle between points A, B, and C.\n",
    "    \n",
    "    The points are given as (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    BA = (A[0] - B[0], A[1] - B[1])\n",
    "    BC = (C[0] - B[0], C[1] - B[1])\n",
    "    magnitude_BA = math.sqrt(BA[0] ** 2 + BA[1] ** 2)\n",
    "    magnitude_BC = math.sqrt(BC[0] ** 2 + BC[1] ** 2)\n",
    "    \n",
    "    if magnitude_BA == 0 or magnitude_BC == 0:\n",
    "        return 0.0\n",
    "\n",
    "    cosine_angle = (BA[0] * BC[0] + BA[1] * BC[1]) / (magnitude_BA * magnitude_BC)\n",
    "    cosine_angle = max(-1.0, min(1.0, cosine_angle))\n",
    "    angle = math.degrees(math.acos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "# Load the trained model for gesture recognition\n",
    "model_path = r'D:\\SpectoV\\Hand_Gesture_Recognition\\research\\addons\\models\\RFC_MOEL_1_A_Z.pkl'\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "# Initialize the HandDetector\n",
    "detector = HandDetector(staticMode=False, maxHands=2, modelComplexity=1, detectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "# Define the list of key points (landmarks)\n",
    "num_landmarks = 21\n",
    "\n",
    "# Dictionary mapping numerical labels to text keys\n",
    "label_map = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S',\n",
    "    19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Function to calculate distances and angles between key points\n",
    "def calculate_features(coords):\n",
    "    distances = []\n",
    "    for i in range(len(coords)):\n",
    "        for j in range(len(coords)):\n",
    "            if i < j:\n",
    "                distance = np.linalg.norm(np.array(coords[i]) - np.array(coords[j]))\n",
    "                distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "# Define the confidence threshold for gesture recognition\n",
    "confidence_threshold = 0.40\n",
    "\n",
    "# Variables to manage gesture recognition\n",
    "sentence = \"\"\n",
    "previous_gesture = \"\"\n",
    "frame_count = 0\n",
    "no_hand_frames = 0\n",
    "recognition_count = 0\n",
    "\n",
    "# Variables to manage keyboard input\n",
    "keys = [\n",
    "    [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"<\"],\n",
    "    [\"Q\", \"W\", \"E\", \"R\", \"T\", \"Y\", \"U\", \"I\", \"O\", \"P\"],\n",
    "    [\"A\", \"S\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \";\"],\n",
    "    [\"Z\", \"X\", \"C\", \"V\", \"B\", \"N\", \"M\", \",\", \".\", \"/\"],\n",
    "    [\"Space\", \"Enter\"]\n",
    "]\n",
    "finalText = \"\"\n",
    "\n",
    "class Button:\n",
    "    def __init__(self, pos, text, size=[60, 60]):  # Adjusted size of the buttons\n",
    "        self.pos = pos\n",
    "        self.size = size\n",
    "        self.text = text\n",
    "\n",
    "def drawAll(img, buttonList):\n",
    "    for button in buttonList:\n",
    "        x, y = button.pos\n",
    "        w, h = button.size\n",
    "        cvzone.cornerRect(img, (button.pos[0], button.pos[1], button.size[0], button.size[1]), 10, rt=4)\n",
    "        cv2.rectangle(img, button.pos, (x + w, y + h), (255, 255, 255), cv2.FILLED)\n",
    "        cv2.putText(img, button.text, (x + 5, y + 30), cv2.FONT_HERSHEY_PLAIN, 2, (150, 150, 150), 2)\n",
    "    return img\n",
    "\n",
    "# Create button list for keyboard interface\n",
    "buttonList = []\n",
    "for i in range(len(keys)):\n",
    "    for j, key in enumerate(keys[i]):\n",
    "        if key == \"Space\":\n",
    "            buttonList.append(Button([450, 80 * i + 90], key, size=[160, 60]))  # Adjusted size for space button\n",
    "        elif key == \"Enter\":\n",
    "            buttonList.append(Button([650, 80 * i + 90], key, size=[160, 60]))  # Adjusted position for enter button\n",
    "        else:\n",
    "            buttonList.append(Button([80 * j + 220, 100 * i + 10], key))\n",
    "\n",
    "# Variables to manage debounce and stability effect for keyboard input\n",
    "lastKeyPressed = None\n",
    "lastPressTime = 0\n",
    "pressCooldown = 0.5  # Time in seconds\n",
    "stableTime = 0.2  # Time in seconds\n",
    "startStableTime = None\n",
    "currentButton = None\n",
    "\n",
    "# Define mode switching key for keyboard\n",
    "MODE_SWITCH_KEY_KEYBOARD = 'm'\n",
    "gesture_mode_active = True  # Start with gesture mode active\n",
    "\n",
    "# Variables for gesture mode switch detection\n",
    "gesture_switch_detection = []\n",
    "\n",
    "# Main loop to switch between modes (gesture and keyboard)\n",
    "while True:\n",
    "    if gesture_mode_active:\n",
    "        # Read a frame from the webcam for gesture recognition\n",
    "        success_gesture, img_gesture = cap_gesture.read()\n",
    "        if not success_gesture:\n",
    "            print(\"Failed to capture gesture image\")\n",
    "            break\n",
    "\n",
    "        # Find hands in the image\n",
    "        hands, img_gesture = detector.findHands(img_gesture, draw=True)\n",
    "\n",
    "        # Initialize lists for storing key points coordinates\n",
    "        left_hand_coords = [(0, 0)] * num_landmarks\n",
    "        right_hand_coords = [(0, 0)] * num_landmarks\n",
    "\n",
    "        # Check if any hands are detected\n",
    "        if hands:\n",
    "            # Reset no_hand_frames count\n",
    "            no_hand_frames = 0\n",
    "            # Loop through each detected hand\n",
    "            for hand in hands:\n",
    "                lmList = hand[\"lmList\"]  # List of 21 landmarks for the current hand\n",
    "                handType = hand[\"type\"]  # Type of the current hand (\"Left\" or \"Right\")\n",
    "\n",
    "                if handType == \"Left\":\n",
    "                    left_hand_coords = [(lm[0], lm[1]) for lm in lmList]\n",
    "                elif handType == \"Right\":\n",
    "                    right_hand_coords = [(lm[0], lm[1]) for lm in lmList]\n",
    "        else:\n",
    "            # Increment no_hand_frames count\n",
    "            no_hand_frames += 1\n",
    "\n",
    "        left_hand_angles = [0.0] * (num_landmarks - 2)\n",
    "        right_hand_angles = [0.0] * (num_landmarks - 2)\n",
    "\n",
    "        if left_hand_coords[0] != (0, 0):  # If left hand is detected\n",
    "            for i in range(1, num_landmarks - 1):\n",
    "                A = left_hand_coords[i - 1]\n",
    "                B = left_hand_coords[i]\n",
    "                C = left_hand_coords[i + 1]\n",
    "                angle = calculate_angle(A, B, C)\n",
    "                left_hand_angles[i - 1] = angle\n",
    "\n",
    "        if right_hand_coords[0] != (0, 0):\n",
    "           for i in range(1, num_landmarks - 1):\n",
    "                A = right_hand_coords[i - 1]\n",
    "                B = right_hand_coords[i]\n",
    "                C = right_hand_coords[i + 1]\n",
    "                angle = calculate_angle(A, B, C)\n",
    "                right_hand_angles[i - 1] = angle\n",
    "\n",
    "        # Combine the coordinates into a single list\n",
    "        angles = left_hand_angles + right_hand_angles\n",
    "        combined_coords = left_hand_coords + right_hand_coords\n",
    "\n",
    "        # Calculate distances and angles between key points for gesture recognition\n",
    "        features = calculate_features(combined_coords)\n",
    "        features = features + angles\n",
    "        # Convert features to DataFrame for prediction\n",
    "        features_df = pd.DataFrame([features])\n",
    "\n",
    "        # Make a prediction if features are available\n",
    "        if not features_df.empty and hands:\n",
    "            probabilities = clf.predict_proba(features_df)\n",
    "            max_prob = np.max(probabilities)\n",
    "            if max_prob >= confidence_threshold:\n",
    "                prediction = clf.predict(features_df)\n",
    "                predicted_gesture = label_map.get(prediction[0], 'Unknown')\n",
    "\n",
    "                # Add to sentence if the gesture is different from the previous one\n",
    "                if predicted_gesture != previous_gesture:\n",
    "                    recognition_count = 1  # Reset the recognition\n",
    "                    previous_gesture = predicted_gesture\n",
    "                else:\n",
    "                    recognition_count += 1\n",
    "\n",
    "                # If the gesture is recognized twice consecutively and it is different from the last character in the sentence, add it to the sentence\n",
    "                if (recognition_count == 1 and (len(sentence) == 0 or predicted_gesture != sentence[-1])) or (recognition_count == 15 and len(sentence) > 0 and predicted_gesture == sentence[-1]):\n",
    "                    sentence += predicted_gesture\n",
    "                    recognition_count = 0  # Reset recognition count for the next gesture\n",
    "                    time.sleep(0.5)  # Wait for 0.5 seconds before recognizing the next gesture\n",
    "\n",
    "                    # Check if \"AAAA\" gesture is recognized to switch modes\n",
    "                    gesture_switch_detection.append(predicted_gesture)\n",
    "                    if len(gesture_switch_detection) > 4:  # Check for \"AAAA\"\n",
    "                        gesture_switch_detection.pop(0)  # Remove oldest entry\n",
    "                        if all(gesture == 'A' for gesture in gesture_switch_detection):\n",
    "                            gesture_mode_active = not gesture_mode_active  # Switch mode\n",
    "                            print(f\"Switched to {'Gesture' if gesture_mode_active else 'Keyboard'} Mode\")\n",
    "                            sentence = \"\"  # Clear sentence after mode switch\n",
    "                            finalText = \"\"  # Clear finalText after mode switch\n",
    "\n",
    "            else:\n",
    "                previous_gesture = \"\"\n",
    "                recognition_count = 0\n",
    "        else:\n",
    "            # Handle case when no hands are detected\n",
    "            if no_hand_frames > 30:  # Adjust this threshold as needed\n",
    "                if sentence and sentence[-1] != ' ':\n",
    "                    sentence += ' '\n",
    "                previous_gesture = \"\"\n",
    "                recognition_count = 0\n",
    "\n",
    "        # Display the gesture recognition result on the image\n",
    "        cv2.putText(img_gesture, f'Gesture Mode - Sentence: {sentence.strip()}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the gesture recognition image\n",
    "        cv2.imshow(\"Hand Gesture Recognition and Keyboard\", img_gesture)\n",
    "\n",
    "    else:\n",
    "        # Read a frame from the webcam for keyboard input\n",
    "        success_keyboard, img_keyboard = cap_keyboard.read()\n",
    "        if not success_keyboard:\n",
    "            print(\"Failed to capture keyboard image\")\n",
    "            break\n",
    "\n",
    "        # Find hands in the image for keyboard interaction\n",
    "        hands, img_keyboard = detector.findHands(img_keyboard, draw=True, flipType=True)\n",
    "        img_keyboard = drawAll(img_keyboard, buttonList)\n",
    "\n",
    "        if hands:\n",
    "            lmListHand = hands[0]['lmList']\n",
    "            for button in buttonList:\n",
    "                x, y = button.pos\n",
    "                w, h = button.size\n",
    "\n",
    "                if x < lmListHand[8][0] < x + w and y < lmListHand[8][1] < y + h:\n",
    "                    if currentButton != button.text:\n",
    "                        startStableTime = time()\n",
    "                        currentButton = button.text\n",
    "\n",
    "                    if currentButton == button.text:\n",
    "                        if startStableTime is not None and time() - startStableTime > stableTime:\n",
    "                            cv2.rectangle(img_keyboard, (x - 5, y - 5), (x + w + 5, y + h + 5), (130, 80, 70), cv2.FILLED)\n",
    "                            cv2.putText(img_keyboard, button.text, (x + 10, y + 40), cv2.FONT_HERSHEY_PLAIN, 2, (200, 200, 200), 2)\n",
    "\n",
    "                            l, _, _ = detector.findDistance((lmListHand[8][0], lmListHand[8][1]),\n",
    "                                                            (lmListHand[12][0], lmListHand[12][1]), img_keyboard)\n",
    "\n",
    "                            currentTime = time()\n",
    "                            if l < 30 and (lastKeyPressed != button.text or (currentTime - lastPressTime) > pressCooldown):\n",
    "                                cv2.rectangle(img_keyboard, button.pos, (x + w, y + h), (230,50,230), cv2.FILLED)\n",
    "                                cv2.putText(img_keyboard, button.text, (x + 10, y + 40), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                                if button.text == \"<\":  # Handle backspace\n",
    "                                    finalText = finalText[:-1]\n",
    "                                elif button.text == \"Space\":  # Handle space\n",
    "                                    finalText += \" \"\n",
    "                                elif button.text == \"Enter\":  # Handle enter\n",
    "                                    print(f\"Keyboard Mode - Text Entered: {finalText}\")\n",
    "                                    finalText = \"\"  # Clear the text after printing\n",
    "                                elif button.text == MODE_SWITCH_KEY_KEYBOARD:  # Handle mode switch key in keyboard mode\n",
    "                                    gesture_mode_active = not gesture_mode_active  # Toggle mode\n",
    "                                    print(f\"Switched to {'Gesture' if gesture_mode_active else 'Keyboard'} Mode\")\n",
    "                                    sentence = \"\"  # Clear sentence after mode switch\n",
    "                                    finalText = \"\"  # Clear finalText after mode switch\n",
    "                                else:\n",
    "                                    finalText += button.text\n",
    "                                lastKeyPressed = button.text\n",
    "                                lastPressTime = currentTime\n",
    "                                startStableTime = None  # Reset stable time after a key press\n",
    "\n",
    "        else:\n",
    "            currentButton = None  # Reset currentButton when no hands are detected\n",
    "\n",
    "        # Display the keyboard interaction result on the image\n",
    "        cv2.putText(img_keyboard, f'Keyboard Mode - Text: {finalText}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the keyboard interaction image\n",
    "        cv2.imshow(\"Hand Gesture Recognition and Keyboard\", img_keyboard)\n",
    "\n",
    "    # Check for mode switching key press ('g' for gesture mode, 'k' for keyboard mode)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('g'):\n",
    "        gesture_mode_active = True\n",
    "        print(\"Switched to Gesture Mode\")\n",
    "    elif key == ord('k'):\n",
    "        gesture_mode_active = False\n",
    "        print(\"Switched to Keyboard Mode\")\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video captures and close windows\n",
    "cap_gesture.release()\n",
    "cap_keyboard.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print the final sentence or text entered\n",
    "print(\"Final Sentence:\", sentence.strip())\n",
    "print(\"Final Text Entered:\", finalText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
